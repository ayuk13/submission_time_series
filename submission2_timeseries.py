# -*- coding: utf-8 -*-
"""submission2_timeseries.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PpdsLoKf29nzsaZBZXIW8xWWvJonZYlC

# **Proyek Dicoding : Membuat Model Machine Learning dengan Data Time Series**

* Nama : Ayu Kirana Vijayanti Indarto
* Email: ayukiranav136@gmail.com
* Dicoding ID: ayukv136
* Linkedin: https://www.linkedin.com/in/ayukiranav136

Proyek ini merupakan proyek untuk mempelajari bagaimana mengembangkan jaringan saraf tiruan untuk masalah Time Series.

## Mengunduh dataset dari kaggle
"""

# install package dengan pip dan upload file json
!pip install -q kaggle
from google.colab import files
files.upload()

# membuat directory
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

# unduh dataset
!kaggle datasets download -d vijayvvenkitesh/microsoft-stock-time-series-analysis

# unzip dataset
!mkdir microsoft-stock-time-series-analysis
!unzip microsoft-stock-time-series-analysis.zip -d microsoft-stock-time-series-analysis
!ls microsoft-stock-time-series-analysis

"""## Membaca dataset dan visualisasi data

Mengimpor library
"""

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt

import tensorflow as tf
from keras.layers import Dense, LSTM
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

"""Import dataset"""

df = pd.read_csv('microsoft-stock-time-series-analysis/Microsoft_Stock.csv', parse_dates=['Date'])
df.head(1000)

"""Cek missing value pada dataset"""

df.isnull().sum()

"""Cek informasi dataset"""

df.info()

"""Membuat plot dari data `Date` dan `Volume`"""

dates = df['Date'].values
vol = df['Volume'].values

plt.figure(figsize=(15,5))
plt.plot(dates, vol)
plt.title('Stock terjual',
          fontsize=20);

vol = vol.reshape(-1,1)
vol

"""## Normalisasi Data"""

min_max_scaler = MinMaxScaler()
volume = min_max_scaler.fit_transform(vol)

"""## Inisialisasi fungsi windowed dataset"""

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
    series = tf.expand_dims(series, axis=-1)
    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))
    ds = ds.shuffle(shuffle_buffer)
    ds = ds.map(lambda w: (w[:-1], w[-1:]))
    return ds.batch(batch_size).prefetch(1)

"""Melakukan split data latih dan data tes"""

date_train, date_test, vol_train, vol_test = train_test_split(dates, volume, test_size = 0.2, shuffle=False)

"""Memanggil fungsi windowed dataset dan membangun model dengan Sequential *model*"""

train_set = windowed_dataset(vol_train, window_size = 60, batch_size=100, shuffle_buffer=1000)
test_set = windowed_dataset(vol_test, window_size = 60, batch_size=100, shuffle_buffer=1000)
model = tf.keras.models.Sequential([
    tf.keras.layers.LSTM(30, return_sequences=True, input_shape=[None, 1]),
    tf.keras.layers.LSTM(60),
    tf.keras.layers.Dense(30, activation="relu"),
    tf.keras.layers.Dense(10, activation="relu"),
    tf.keras.layers.Dense(1),
])

"""Menentukan threshold mae"""

threshold_mae = (volume.max() - volume.min()) * 10/100
print(threshold_mae)

"""Meninisialisasi fungsi callback"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae') < threshold_mae):
      print("MAE kurang dari 10%, hentikan training!")
      self.model.stop_training = True
callbacks = myCallback()

"""Melakukan training pada model"""

optimizer = tf.keras.optimizers.SGD(lr=1.0000e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])

history = model.fit(train_set,
                    epochs=100,
                    validation_data=test_set,
                    verbose=2,
                    callbacks=[callbacks])